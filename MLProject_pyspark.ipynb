{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Obtaining dependency information for mlflow from https://files.pythonhosted.org/packages/d7/70/167ba0b7bf8912571af0f22711122ed5eb0c71c250e0d9e8c045b60b4a62/mlflow-2.11.1-py3-none-any.whl.metadata\n",
      "  Downloading mlflow-2.11.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (3.0.0)\n",
      "Collecting entrypoints<1 (from mlflow)\n",
      "  Obtaining dependency information for entrypoints<1 from https://files.pythonhosted.org/packages/35/a8/365059bbcd4572cbc41de17fd5b682be5868b218c3c5479071865cab9078/entrypoints-0.4-py3-none-any.whl.metadata\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython<4,>=3.1.9 (from mlflow)\n",
      "  Obtaining dependency information for gitpython<4,>=3.1.9 from https://files.pythonhosted.org/packages/67/c7/995360c87dd74e27539ccbfecddfb58e08f140d849fcd7f35d2ed1a5f80f/GitPython-3.1.42-py3-none-any.whl.metadata\n",
      "  Downloading GitPython-3.1.42-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (4.25.0)\n",
      "Requirement already satisfied: pytz<2025 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (2023.3.post1)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (2.31.0)\n",
      "Requirement already satisfied: packaging<24 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (23.1)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (6.8.0)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow)\n",
      "  Obtaining dependency information for sqlparse<1,>=0.4.0 from https://files.pythonhosted.org/packages/98/5a/66d7c9305baa9f11857f247d4ba761402cea75db6058ff850ed7128957b7/sqlparse-0.4.4-py3-none-any.whl.metadata\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Obtaining dependency information for alembic!=1.10.0,<2 from https://files.pythonhosted.org/packages/7f/50/9fb3a5c80df6eb6516693270621676980acd6d5a9a7efdbfa273f8d616c7/alembic-1.13.1-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Obtaining dependency information for docker<8,>=4.0.0 from https://files.pythonhosted.org/packages/18/bd/9706c10bb12e05043ef138dc8d412cfd17f29c8df0fb28ad71c96a98785d/docker-7.0.0-py3-none-any.whl.metadata\n",
      "  Downloading docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: Flask<4 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: numpy<2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (1.26.3)\n",
      "Requirement already satisfied: scipy<2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (1.11.4)\n",
      "Requirement already satisfied: pandas<3 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (2.2.0)\n",
      "Collecting querystring-parser<2 (from mlflow)\n",
      "  Obtaining dependency information for querystring-parser<2 from https://files.pythonhosted.org/packages/88/6b/572b2590fd55114118bf08bde63c0a421dcc82d593700f3e2ad89908a8a9/querystring_parser-1.2.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (2.0.23)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (1.3.2)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (14.0.1)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (3.5.1)\n",
      "Requirement already satisfied: matplotlib<4 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (3.8.1)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Obtaining dependency information for graphene<4 from https://files.pythonhosted.org/packages/24/70/96f6027cdfc9bb89fc07627b615cb43fb1c443c93498412beaeaf157e9f1/graphene-3.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting gunicorn<22 (from mlflow)\n",
      "  Obtaining dependency information for gunicorn<22 from https://files.pythonhosted.org/packages/0e/2a/c3a878eccb100ccddf45c50b6b8db8cf3301a6adede6e31d48e8531cab13/gunicorn-21.2.0-py3-none-any.whl.metadata\n",
      "  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from mlflow) (3.1.2)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/2b/8d/9f11d0b9ac521febb806e7f30dc5982d0f4f5821217712c59005fbc5c1e3/Mako-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading Mako-1.3.2-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow) (4.8.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.18)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from Flask<4->mlflow) (1.7.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow)\n",
      "  Obtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Obtaining dependency information for graphql-core<3.3,>=3.1 from https://files.pythonhosted.org/packages/f8/39/e5143e7ec70939d2076c1165ae9d4a3815597019c4d797b7f959cf778600/graphql_core-3.2.3-py3-none-any.whl.metadata\n",
      "  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Obtaining dependency information for graphql-relay<3.3,>=3.1 from https://files.pythonhosted.org/packages/74/16/a4cf06adbc711bd364a73ce043b0b08d8fa5aae3df11b6ee4248bcdad2e0/graphql_relay-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow)\n",
      "  Obtaining dependency information for aniso8601<10,>=8 from https://files.pythonhosted.org/packages/e3/04/e97c12dc034791d7b504860acfcdd2963fa21ae61eaca1c9d31245f812c3/aniso8601-9.0.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from pandas<3->mlflow) (2023.3)\n",
      "Requirement already satisfied: six in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/fmedrano/miniconda3/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow)\n",
      "  Obtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading mlflow-2.11.1-py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m840.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m344.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m660.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m99.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m95.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m962.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m55.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m593.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m128.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: aniso8601, sqlparse, smmap, querystring-parser, Mako, gunicorn, graphql-core, entrypoints, graphql-relay, gitdb, docker, alembic, graphene, gitpython, mlflow\n",
      "Successfully installed Mako-1.3.2 alembic-1.13.1 aniso8601-9.0.1 docker-7.0.0 entrypoints-0.4 gitdb-4.0.11 gitpython-3.1.42 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-21.2.0 mlflow-2.11.1 querystring-parser-1.2.4 smmap-5.0.1 sqlparse-0.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo que se esta siguiendo: https://towardsdatascience.com/finding-donors-classification-project-with-pyspark-485fb3c94e5e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\"\"\" ML Flow packages \"\"\"\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.sklearn        \n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec      \n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/08 12:58:09 WARN Utils: Your hostname, fmedrano resolves to a loopback address: 127.0.1.1; using 192.168.0.18 instead (on interface wlp0s20f3)\n",
      "24/03/08 12:58:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/08 12:58:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Example DataFrame\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: int, Workclass: string, Final Weight: int, Education: string, EducationNum: int, Marital Status: string, Occupation: string, Relationship: string, Race: string, Gender: string, Capital Gain: int, capital loss: int, Hours per Week: int, Native Country: string, Income: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cargamos el archivo \n",
    "file_location = \"adult.csv\"\n",
    "file_type = \"csv\"\n",
    "# CSV options\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "# The applied options are for CSV files. For other file types, these will be ignored.\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+------------+-------------+------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "|Age|        Workclass|Final Weight|    Education|EducationNum|      Marital Status|        Occupation|  Relationship|               Race| Gender|Capital Gain|capital loss|Hours per Week|Native Country|Income|\n",
      "+---+-----------------+------------+-------------+------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "| 39|        State-gov|       77516|    Bachelors|          13|       Never-married|      Adm-clerical| Not-in-family|              White|   Male|        2174|           0|            40| United-States| <=50K|\n",
      "| 50| Self-emp-not-inc|       83311|    Bachelors|          13|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|           0|           0|            13| United-States| <=50K|\n",
      "| 38|          Private|      215646|      HS-grad|           9|            Divorced| Handlers-cleaners| Not-in-family|              White|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 53|          Private|      234721|         11th|           7|  Married-civ-spouse| Handlers-cleaners|       Husband|              Black|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 28|          Private|      338409|    Bachelors|          13|  Married-civ-spouse|    Prof-specialty|          Wife|              Black| Female|           0|           0|            40|          Cuba| <=50K|\n",
      "| 37|          Private|      284582|      Masters|          14|  Married-civ-spouse|   Exec-managerial|          Wife|              White| Female|           0|           0|            40| United-States| <=50K|\n",
      "| 49|          Private|      160187|          9th|           5| Married-spouse-a...|     Other-service| Not-in-family|              Black| Female|           0|           0|            16|       Jamaica| <=50K|\n",
      "| 52| Self-emp-not-inc|      209642|      HS-grad|           9|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|           0|           0|            45| United-States|  >50K|\n",
      "| 31|          Private|       45781|      Masters|          14|       Never-married|    Prof-specialty| Not-in-family|              White| Female|       14084|           0|            50| United-States|  >50K|\n",
      "| 42|          Private|      159449|    Bachelors|          13|  Married-civ-spouse|   Exec-managerial|       Husband|              White|   Male|        5178|           0|            40| United-States|  >50K|\n",
      "| 37|          Private|      280464| Some-college|          10|  Married-civ-spouse|   Exec-managerial|       Husband|              Black|   Male|           0|           0|            80| United-States|  >50K|\n",
      "| 30|        State-gov|      141297|    Bachelors|          13|  Married-civ-spouse|    Prof-specialty|       Husband| Asian-Pac-Islander|   Male|           0|           0|            40|         India|  >50K|\n",
      "| 23|          Private|      122272|    Bachelors|          13|       Never-married|      Adm-clerical|     Own-child|              White| Female|           0|           0|            30| United-States| <=50K|\n",
      "| 32|          Private|      205019|   Assoc-acdm|          12|       Never-married|             Sales| Not-in-family|              Black|   Male|           0|           0|            50| United-States| <=50K|\n",
      "| 40|          Private|      121772|    Assoc-voc|          11|  Married-civ-spouse|      Craft-repair|       Husband| Asian-Pac-Islander|   Male|           0|           0|            40|             ?|  >50K|\n",
      "| 34|          Private|      245487|      7th-8th|           4|  Married-civ-spouse|  Transport-moving|       Husband| Amer-Indian-Eskimo|   Male|           0|           0|            45|        Mexico| <=50K|\n",
      "| 25| Self-emp-not-inc|      176756|      HS-grad|           9|       Never-married|   Farming-fishing|     Own-child|              White|   Male|           0|           0|            35| United-States| <=50K|\n",
      "| 32|          Private|      186824|      HS-grad|           9|       Never-married| Machine-op-inspct|     Unmarried|              White|   Male|           0|           0|            40| United-States| <=50K|\n",
      "| 38|          Private|       28887|         11th|           7|  Married-civ-spouse|             Sales|       Husband|              White|   Male|           0|           0|            50| United-States| <=50K|\n",
      "| 43| Self-emp-not-inc|      292175|      Masters|          14|            Divorced|   Exec-managerial|     Unmarried|              White| Female|           0|           0|            45| United-States|  >50K|\n",
      "+---+-----------------+------------+-------------+------------+--------------------+------------------+--------------+-------------------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the \"Age\" column from string to double\n",
    "df = df.withColumn(\"Age\", col(\"Age\").cast(\"int\"))\n",
    "df = df.withColumn(\"EducationNum\", col(\"EducationNum\").cast(\"int\"))\n",
    "df = df.withColumn(\"Capital Gain\", col(\"Capital Gain\").cast(\"double\"))\n",
    "df = df.withColumn(\"Capital Loss\", col(\"Capital Loss\").cast(\"double\"))\n",
    "df = df.withColumn(\"Hours per Week\", col(\"Hours per Week\").cast(\"double\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Age: string, Workclass: string, Final Weight: string, Education: string, EducationNum: string, Marital Status: string, Occupation: string, Relationship: string, Race: string, Gender: string, Capital Gain: string, Capital Loss: string, Hours per Week: string, Native Country: string, Income: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Workclass',\n",
       " 'Final Weight',\n",
       " 'Education',\n",
       " 'EducationNum',\n",
       " 'Marital Status',\n",
       " 'Occupation',\n",
       " 'Relationship',\n",
       " 'Race',\n",
       " 'Gender',\n",
       " 'Capital Gain',\n",
       " 'Capital Loss',\n",
       " 'Hours per Week',\n",
       " 'Native Country',\n",
       " '>50K']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.Prepare the data\n",
    "# Import pyspark functions\n",
    "from pyspark.sql import functions as F\n",
    "# Create add new column to the dataset\n",
    "df = df.withColumn('>50K', F.when(df.Income == '<=50K', 0).otherwise(1))\n",
    "# Drop the Income label\n",
    "df = df.drop('Income')\n",
    "# Show dataset's columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: int, Workclass: string, Final Weight: int, Education: string, EducationNum: int, Marital Status: string, Occupation: string, Relationship: string, Race: string, Gender: string, Capital Gain: double, Capital Loss: double, Hours per Week: double, Native Country: string, >50K: int, Workclass_indexed: double, Education_indexed: double, Marital Status_indexed: double, Occupation_indexed: double, Relationship_indexed: double, Race_indexed: double, Gender_indexed: double, Hours per Week_indexed: double, Native Country_indexed: double, Workclass_indexed_encoded: vector, Education_indexed_encoded: vector, Marital Status_indexed_encoded: vector, Occupation_indexed_encoded: vector, Relationship_indexed_encoded: vector, Race_indexed_encoded: vector, Gender_indexed_encoded: vector, Hours per Week_indexed_encoded: vector, Native Country_indexed_encoded: vector, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vectorizing Numerical Features and One-Hot Encodin Categorical Features \n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier, LogisticRegression)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Selecting categorical features\n",
    "categorical_columns = [\n",
    " 'Workclass',\n",
    " 'Education',\n",
    " 'Marital Status',\n",
    " 'Occupation',\n",
    " 'Relationship',\n",
    " 'Race',\n",
    " 'Gender',\n",
    " 'Hours per Week',\n",
    " 'Native Country',\n",
    " ]\n",
    "# The index of string values multiple columns\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "    for c in categorical_columns]\n",
    "# The encode of indexed values multiple columns\n",
    "encoders = [OneHotEncoder(dropLast=False,inputCol=indexer.getOutputCol(),\n",
    "            outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) \n",
    "    for indexer in indexers]\n",
    "\n",
    "# Vectorizing encoded values\n",
    "categorical_encoded = [encoder.getOutputCol() for encoder in encoders]\n",
    "numerical_columns = ['Age', 'EducationNum', 'Capital Gain', 'Capital Loss']\n",
    "inputcols = categorical_encoded + numerical_columns\n",
    "assembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=indexers + encoders+[assembler])\n",
    "model = pipeline.fit(df)\n",
    "# Transform data\n",
    "transformed = model.transform(df)\n",
    "display(transformed)\n",
    "\n",
    "# Transform data\n",
    "final_data = transformed.select('features', '>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train.drop('>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "|(200,[0,9,25,32,4...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/416436688303622593', creation_time=1709904237106, experiment_id='416436688303622593', last_update_time=1709904237106, lifecycle_stage='active', name='MLFLow_Model', tags={}>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define MLflow tracking URI (optional)\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"MLFLow_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/08 14:34:05 ERROR Instrumentation: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"mlflow-artifacts\"\n",
      "\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n",
      "\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n",
      "\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n",
      "\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n",
      "\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:673)\n",
      "\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n",
      "\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model logged in run 8f6ab2799c57408cb74703a9c1ed720a\n"
     ]
    }
   ],
   "source": [
    "# Model implementation\n",
    "with mlflow.start_run() as run:\n",
    "    rfc = RandomForestClassifier(numTrees=150, labelCol='>50K', featuresCol='features')\n",
    "    df_train, df_test = final_data.randomSplit([0.8,0.2])\n",
    "    rfc_model = rfc.fit(df_train)\n",
    "    #model_signature = infer_signature(df_train.drop('>50K'), rfc_model.transform(df_test.limit(1)).select(\">50K\")) # coge la signatura como el tipo de output/inpt que espera\n",
    "    mlflow.spark.log_model(rfc_model, 'model')\n",
    "    print('Model logged in run {}'.format(run.info.run_uuid))\n",
    "    mlflow.log_metric(\"foo\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating model performance \n",
    "my_eval = BinaryClassificationEvaluator(labelCol='>50K')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
